{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_path = '/content/drive/My Drive/Colab Notebooks/Save/'\n",
        "import os\n",
        "# 创建路径如果它不存在\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "previous_checkpoint = None  # 用来追踪上一个checkpoint的文件名\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),  # 随机旋转\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # 颜色抖动\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) #训练数据集\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for _, (x, y) in enumerate(trainset):\n",
        "  print(x.shape, y)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "for _, (x, y) in enumerate(trainloader):\n",
        "  print(x.shape, y)\n",
        "  break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"你正在使用：{device}\")\n",
        "\n",
        "# 深度可分离卷积模块\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# 残差块定义\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            DepthwiseSeparableConv(inchannel, outchannel, stride=stride),\n",
        "            DepthwiseSeparableConv(outchannel, outchannel, stride=1)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.left(x)\n",
        "        shortcut = self.shortcut(identity)\n",
        "        out = out + shortcut  # Use out = out + shortcut instead of out += shortcut to ensure it's not inplace\n",
        "        out = F.relu(out, inplace=False)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ResNet主体架构\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.layer1 = self.make_layer(block, 64,  1, stride=1)\n",
        "        self.layer2 = self.make_layer(block, 128, 1, stride=2)\n",
        "        self.layer3 = self.make_layer(block, 256, 1, stride=2)\n",
        "        self.layer4 = self.make_layer(block, 512, 1, stride=2)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# 实例化模型并移至设备\n",
        "def ResNet18():\n",
        "    return ResNet(ResidualBlock, num_classes=10)\n",
        "\n",
        "net = ResNet18().to(device)\n",
        "print(net)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calc_param(model: nn.Module) -> int:\n",
        "    params = list(model.parameters())\n",
        "    param_size = 0\n",
        "    for _param in params:\n",
        "        _param_size = 1\n",
        "        for _ in _param.size():\n",
        "            _param_size *= _\n",
        "        param_size += _param_size\n",
        "    return param_size\n",
        "\n",
        "print(f\"The number of model parameters is:{calc_param(net)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "# 定义学习率调度器\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "\n",
        "\n",
        "def load_checkpoint(model, optimizer, scheduler, filename='model_checkpoint.pth'):\n",
        "    # 注意: 输入模型 & 优化器需要预先定义\n",
        "    checkpoint = torch.load(filename)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "\n",
        "    # 也可以加载其他数据，例如 epoch 数或损失\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    return model, optimizer, scheduler, epoch, loss\n",
        "\n",
        "# 例子：加载状态\n",
        "checkpoint_path = os.path.join(save_path, f'model_checkpoint_33.pth')\n",
        "model, optimizer, scheduler, start_epoch, val_loss = load_checkpoint(net, optimizer, scheduler, checkpoint_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_validation_loss(model, val_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total_count = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            total_loss += loss.item() * x.size(0)  # Multiply loss by batch size\n",
        "            total_count += x.size(0)\n",
        "\n",
        "    average_loss = total_loss / total_count\n",
        "    return average_loss\n",
        "\n",
        "for epoch in range(1):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (x, y) in enumerate(trainloader, 0):\n",
        "        inputs, labels = x.to(device), y.to(device)\n",
        "        # 参数梯度置 0\n",
        "        optimizer.zero_grad()\n",
        "        # 前向推理\n",
        "        outputs = net(inputs)\n",
        "        # 计算损失\n",
        "        loss = criterion(outputs, labels)\n",
        "        # 后向传递梯度计算\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f\"[EPOCH {epoch + 1:03} | IT {batch_idx + 1:05}] LOSS: {running_loss / batch_idx: .3f}\")\n",
        "    # 假设val_loss是你在验证集上计算得到的损失\n",
        "    val_loss = compute_validation_loss(net, trainloader, device)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "    # 保存模型权重、优化器和调度器状态\n",
        "    # 删除上一个checkpoint\n",
        "    if previous_checkpoint is not None:\n",
        "        try:\n",
        "            os.remove(previous_checkpoint)\n",
        "            print(f\"Removed previous checkpoint: {previous_checkpoint}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error: {previous_checkpoint} : {e.strerror}\")\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': net.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'loss': val_loss,\n",
        "    }\n",
        "    checkpoint_path = os.path.join(save_path, f'model_checkpoint_{epoch+1}.pth')\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    # 更新previous_checkpoint变量\n",
        "    previous_checkpoint = checkpoint_path\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calc_acc(model: nn.Module, testloader: torch.utils.data.DataLoader) -> float:\n",
        "  net.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for _, (x, y) in enumerate(testloader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      outputs = model(x)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "\n",
        "  return correct / total\n",
        "\n",
        "\n",
        "print(f\"\"\"\n",
        "- 模型参数量：{calc_param(net)}\n",
        "- 模型测试准确率：{calc_acc(net, testloader)}\"\"\")"
      ],
      "metadata": {
        "id": "K8SGTY6if3SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 课程任务\n",
        "\n",
        "---\n",
        "\n",
        "你需要自己从头开始设计和创建一个分类器，在 CIFAR 10 数据上进行训练和测试。\n",
        "\n",
        "要求：\n",
        "- 模型参数量不超过 `ResNet18`，即 11689512 ，（通过 `calc_param(torchvision.models.resnet18())`计算得到）。\n",
        "- 模型达到尽可能高的准确率。"
      ],
      "metadata": {
        "id": "3Nr_YXJCqgp5"
      }
    }
  ]
}